---
layout: page
title: SPHRED for Dialog modeling
description: Rebuilding a Conditional Variational Framework for Dialog Generation
img: assets/img/work4_noncollapse_distr.gif
importance: 4
category: research
---

This is a research project for my graduation thesis at International University, Vietnam National University - HCMC.

SPHRED is a combination of Conditional Variational Autoencoder and Hierarchical Recurrent Encoder Decoder for controllable dialog generation. 

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/work4_sphred.png" title="SPHRED architecture" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    SPHRED architecture includes a Hierarchical Recurrent Encoder-Decoder (HRED, comprises of an encoder RNN, a context RNN, and a decoder RNN) for dialog generation and a conditional variational autoencoder for controllability.
</div>

To gain a better understanding of the VAE optimization, I used PCA to visualize in 2D the prior and posterior distributions while training, and observed that as posterior collapse happens (the 2 distributions move away from each other), the model starts to generate repeating tokens (greedy sampling).

<div class="row justify-content-sm-center">
    <div class="col-sm-5 mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/work4_collapse_distr.gif" title="posterior collapse" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm-7 mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/work4_collapse_tokens.png" title="repeated tokens" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Changes of separate-overlap-separate in prior and posterior distributions as training took place, recorded 10 training steps (left); repeated tokens generated by the model (right).
</div>

I later found that nucleus sampling, while prevent the model from generating repeating sequences, also resolves posterior collapse (the overlap of distributions was well maintained throughout the process). However, this disabled the controllability offered by CVAE.

<div class="row justify-content-sm-center">
    <div class="col-sm-5 mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/work4_noncollapse_distr.gif" title="non-posterior-collapse" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm-7 mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/work4_noncollapse_tokens.png" title="varied tokens" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Changes of separate-overlap in prior and posterior distributions as training took place, recorded 10 training steps (left); varied tokens generated by the model (right).
</div>

Watch my presentation on this project here:

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include video.liquid loading="eager" path="assets/video/presentation.mp4" class="img-fluid rounded z-depth-1" controls=true %}
    </div>
</div>
<div class="caption">
    A presentation on the model architecture, optimization, and results.
</div>

More information can be found [here](https://github.com/hieuchi911/sphred_from_vhred).