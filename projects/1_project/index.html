<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Distillation mitigates Hallucinations | Hieu Tran-Chi Nguyen </title> <meta name="author" content="Hieu Tran-Chi Nguyen"> <meta name="description" content="On the effects of Knowledge Distillation on LLM Hallucinations"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, hieu-nguyen-ortfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hieuchi911.github.io/projects/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Hieu Tran-Chi Nguyen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Distillation mitigates Hallucinations</h1> <p class="post-description">On the effects of Knowledge Distillation on LLM Hallucinations</p> </header> <article> <h5><b>Motivation</b></h5> <p>In my senior year of masters, I conducted some analysis on the optimization aspect in traditional training of decoder transformers with One Hot Encoding (OHE) target distributions and found that: <b><i>by optimizing models against OHE targets of zero entropy, we train them to make assumptions</i></b> (<a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy#:~:text=To%20choose%20a%20distribution%20with%20lower%20entropy%20would%20be%20to%20assume%20information%20we%20do%20not%20possess" rel="external nofollow noopener" target="_blank">principle of Maximum Entropy</a> states that to choose a distribution with entropy lower than allowed by the provided information would be to assume information we do not possess).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_maxentropy-480.webp 480w,/assets/img/work1_maxentropy-800.webp 800w,/assets/img/work1_maxentropy-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_maxentropy.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="OHE targets cause hallucinations" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Given the context "The student did well in", the distribution of the next token should have high probability for subjects, sports, arts, etc. However, OHE targets force the model to choose one token with 100% probability to be "Physics", an information not provided in the context. Thus, the model learns to make assumptions and thus hallucinate. </div> <p>I hypothesized that this leads to hallucination and that distribution-based Knowledge Distillation (KD), replacing OHE targets with teacher context-aware distributions, avoids assumptions and helps reduce hallucination.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_kdhelps-480.webp 480w,/assets/img/work1_kdhelps-800.webp 800w,/assets/img/work1_kdhelps-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_kdhelps.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="OHE targets cause hallucinations" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Replace OHE targets with context-aware distributions (non-zero probability for other possibilities, e.g. Maths, Arts, English) from a teacher model, the model learns to generate tokens that are more contextually relevant and less hallucinatory. </div> <p>I began working with <a href="https://zihaohe123.github.io/" rel="external nofollow noopener" target="_blank">senior PhD student Zihao He</a> at <a href="https://lermanlab.github.io/" rel="external nofollow noopener" target="_blank">SEA (Socially-Embedded AI) Lab</a> led by Professor <a href="https://www.isi.edu/people/lerman/about" rel="external nofollow noopener" target="_blank">Kristina Lerman</a> to study the effects of KD on LLM Hallucinations.</p> <h5><b>Experiments</b></h5> <p>To verify my hypothesis, I instruction finetuned 7B pretrained LLMs under two methods: traditional <b>Supervised Fine-Tuning (SFT)</b> as baselines and <b>KD</b> (with 13B-70B teachers), and then compare them using a robust hallucination evaluation pipeline. Advised by Cohere For AI researchers, I evaluated them with benchmarks of summarization tasks, using external metrics (rougeL, <a href="https://vectara.com/blog/hhem-v2-a-new-and-improved-factual-consistency-scoring-model/" rel="external nofollow noopener" target="_blank">factual consistency</a> from Vectara) that compares predictions to ground truths and novel internal metrics (attention rates from <a href="https://arxiv.org/abs/2407.07071" rel="external nofollow noopener" target="_blank">LookbackLens for hallucination detection</a>) that compares predictions to contexts.</p> <h5><b>Results</b></h5> <p>So far, we have seen decent improvements of KD models over SFT baselines across metrics and benchmarks. These results have consolidated the hypothesis, as well as the trustworthiness of mainstream metrics by its consistency with the novel internal metrics.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_res_rougel-480.webp 480w,/assets/img/work1_res_rougel-800.webp 800w,/assets/img/work1_res_rougel-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_res_rougel.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_res_attrates-480.webp 480w,/assets/img/work1_res_attrates-800.webp 800w,/assets/img/work1_res_attrates-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_res_attrates.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Boxplots of HPO experiments: SFT baseline and KD models with lambda_KD of 0.1, 1.0, 10.0 (KD is aggregate of lambda_KD of 0.1, 1.0, 10.0) for RougeL (left) and attention rates (right) </div> <p>An interesting observation is that factual consistency (or support rate), while show similar patterns as RougeL and attention rates, gave very low scores for human labels. This suggests that factual consistency might not fully reflect hallucination (<a href="https://github.com/vectara/hallucination-leaderboard#:~:text=Wouldn%27t%20an%20extractive%20summarizer%20model%20that%20just%20copies%20and%20pastes%20from%20the%20original%20summary%20score%20100%25%20(0%20hallucination)%20on%20this%20task" rel="external nofollow noopener" target="_blank">as pointed out</a> in their repository):</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_res_vectara-480.webp 480w,/assets/img/work1_res_vectara-800.webp 800w,/assets/img/work1_res_vectara-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_res_vectara.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> </div> <p>Prior to this, we also got similar results for models of size 300M-1B.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_res_sLLM_QA-480.webp 480w,/assets/img/work1_res_sLLM_QA-800.webp 800w,/assets/img/work1_res_sLLM_QA-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_res_sLLM_QA.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model (fine-tuned with Llama as the teacher on the PubMedQA dataset) Evaluation Results on Truthful QA and Hotpot QA for Q&amp;A task </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/work1_res_sLLM_summ-480.webp 480w,/assets/img/work1_res_sLLM_summ-800.webp 800w,/assets/img/work1_res_sLLM_summ-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/work1_res_sLLM_summ.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model (fine-tuned with Mistral as the teacher on the DialogSum dataset) Evaluation Results on CNN Dailymail for summarization task </div> <p>As we progress, we want to verify the hypothesis with more model families like Llama3.1, Mistral, and Qwen.</p> <h5><b>Future works</b></h5> <p>There are many questions that I want to explore next:</p> <ul> <li>Does a model’s tendency to generate inaccurate information from its internal knowledge (factual hallucination) lead to generation of inaccurate responses when given contexts (faithfulness hallucination)? Could addressing the former also mitigate the latter?</li> <li>Are acquired improvements on external metrics were merely due to better task fulfillment instead of hallucination-free reasoning? This is because these metrics only compare prediction text to ground truth text, while hallucination can be subtle and requires non-trivial reasoning to identify. In fact, we’ve already started tackling this question with internal metrics and proved the effectiveness of external metrics.</li> <li>Other factors causing hallucination: exposure bias, data imbalance, attend-to-all mechanism that distract models, etc.</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hieu Tran-Chi Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: November 27, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>